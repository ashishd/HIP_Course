{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49390830-5c18-41f4-9f1d-18bddc857edd",
   "metadata": {},
   "source": [
    "# Optimising compute with concurrent IO in HIP\n",
    "\n",
    "With many iterative processes there is a need to get information **off** the device at regular intervals. Up to this point we have been transferring data off the compute device **after** kernel execution. Furthermore, the routines to read information from device buffers have thus far been used in a blocking manner, that is the program pauses while the read occurs. Most compute devices have the ability to transfer data **while** kernels are being executed. This means IO transfers can take place during compute and may in some instances **take place entirely** during kernel execution. For the cost of additional programming complexity, significant compute savings can be obtained, as the following diagram illustrates:\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/optimising_io.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: The difference between sequential and concurrent IO.</figcaption>\n",
    "</figure>\n",
    "\n",
    "## Concurrent IO is enabled with multiple streams\n",
    "\n",
    "The **key to leveraging concurrent IO** is to perform compute and IO in different streams. Then IO operations can take place **largely independently** of the compute operations. HIP events and the **hipStreamSynchronize** command can help establish dependencies between streams. Non-blocking asynchronous IO calls are also vital for concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04ce78-df29-42dd-a38a-822a23407cae",
   "metadata": {},
   "source": [
    "## Example with the 2D wave equation\n",
    "\n",
    "The [scalar wave equation](https://en.wikipedia.org/wiki/Wave_equation) adequately describes the propagation of waves. If **U** is a 2D grid storing the amplitude of the wave at every location (the wavefield), **V** is a 2D grid storing velocity, and **t** is time, then 2D waves propagate according to the formula,\n",
    "\n",
    "$$\\frac{\\partial^2 \\textbf{U}}{{\\partial t}^2}=\\textbf{V}^2 \\left (\\frac{\\partial^2 \\textbf{U}}{{\\partial x_{0}}^2}+\\frac{\\partial^2 \\textbf{U}}{{\\partial x_{1}}^2} \\right)+f(t)$$\n",
    "\n",
    "where $x_0$ and $x_1$ are spatial directions and $f(t)$ is a forcing term. If $\\Delta t$ is the time step a second-order finite-difference approximation to the time derivative is given in terms of the amplitude at timesteps $\\textbf{U}_{0}, \\textbf{U}_{1}$ and $\\textbf{U}_{2}.$ \n",
    "\n",
    "$$\\frac{\\partial^2 \\textbf{U}}{{\\partial t}^2} \\approx \\frac{1}{\\Delta t^2} \\left ( \\textbf{U}_{0} -2 \\textbf{U}_{1}+\\textbf{U}_{2} \\right ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78810535-577b-4789-a36c-d5a43d759bd7",
   "metadata": {},
   "source": [
    "Replace $\\frac{\\partial^2 \\textbf{U}}{{\\partial t}^2}$ with $\\frac{1}{\\Delta t^2} \\left( \\textbf{U}_{0} -2 \\textbf{U}_{1}+\\textbf{U}_{2} \\right )$ and solve for $\\textbf{U}_{2}$.\n",
    "\n",
    "$$\\textbf{U}_{2} \\approx 2 \\textbf{U}_{1} - \\textbf{U}_{0} + \\Delta t^2\\textbf{V}^2 \\left (\\frac{\\partial^2 \\textbf{U}_{1}}{{\\partial x_{0}}^2}+\\frac{\\partial^2 \\textbf{U}_{1}}{{\\partial x_{1}}^2} \\right)+f_{1}$$\n",
    "\n",
    "This is an iterative formula to generate the amplitude at the next timestep $\\textbf{U}_2$ if we know the present ampltiude $\\textbf{U}_{1}$ and past amplitude $\\textbf{U}_{0}.$ We also use finite difference approximations for the spatial derivatives, and express the spatial derivatives as a matrix multiplied by $\\textbf{U}_{1}$, but this complexity is unnecessary to show here. All we need to know is that the next timestep is a function ${\\textbf{F}}$ of the present and past timesteps, the velocity, and the forcing term.\n",
    "\n",
    "$$\\textbf{U}_{2}=\\textbf{F}(\\textbf{U}_0, \\textbf{U}_1, \\textbf{V}, f_{1})$$\n",
    "\n",
    "> In geophysics we usually use a [Ricker Wavelet](https://wiki.seg.org/wiki/Dictionary:Ricker_wavelet) for the forcing term $f$, and usually inject that wavelet into one cell within the grid as time progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9870e-642e-4357-a49a-bf220fd42d7c",
   "metadata": {},
   "source": [
    "### Kernel implementation\n",
    "\n",
    "In both [wave2d_sync.cpp](wave2d_sync.cpp) and [wave2d_async.cpp](wave2d_async.cpp) is a kernel called **wave2d_4o** that implements the function **F**. HIP device allocations store $\\textbf{U}_{0}, \\textbf{U}_{1}, \\textbf{U}_{2}$, and $\\textbf{V}$ on the compute device.\n",
    "\n",
    "```C++\n",
    "// Kernel to solve the wave equation with fourth-order accuracy in space\n",
    "__global__ void wave2d_4o (\n",
    "        // Arguments\n",
    "        float_type* U0,\n",
    "        float_type* U1,\n",
    "        float_type* U2,\n",
    "        float_type* V,\n",
    "        size_t N0,\n",
    "        size_t N1,\n",
    "        float dt2,\n",
    "        float inv_dx02,\n",
    "        float inv_dx12,\n",
    "        // Position, frequency, and time for the\n",
    "        // wavelet injection\n",
    "        size_t P0,\n",
    "        size_t P1,\n",
    "        float pi2fm2t2) {    \n",
    "\n",
    "    // U2, U1, U0, V is of size (N0, N1)\n",
    "    size_t i0 = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    size_t i1 = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Required padding and coefficients for spatial finite difference\n",
    "    const int pad_l=2, pad_r=2, ncoeffs=5;\n",
    "    float coeffs[ncoeffs] = {-0.083333336f, 1.3333334f, -2.5f, 1.3333334f, -0.083333336f};\n",
    "    \n",
    "    // Limit i0 and i1 to the region of U2 within the padding\n",
    "    i0=min(i0, (size_t)(N0-1-pad_r));\n",
    "    i1=min(i1, (size_t)(N1-1-pad_r));\n",
    "    i0=max((size_t)pad_l, i0);\n",
    "    i1=max((size_t)pad_l, i1);\n",
    "    \n",
    "    // Position within the grid as a 1D offset\n",
    "    long offset=i0*N1+i1;\n",
    "    \n",
    "    // Temporary storage\n",
    "    float temp0=0.0f, temp1=0.0f;\n",
    "    float tempV=V[offset];\n",
    "    \n",
    "    // Calculate the Laplacian\n",
    "    for (long n=0; n<ncoeffs; n++) {\n",
    "        // Stride in dim0 is N1        \n",
    "        temp0+=coeffs[n]*U1[offset+(n*(long)N1)-(pad_l*(long)N1)];\n",
    "        // Stride in dim1 is 1\n",
    "        temp1+=coeffs[n]*U1[offset+n-pad_l];\n",
    "    }\n",
    "    \n",
    "    // Calculate the wavefield U2 at the next timestep\n",
    "    U2[offset]=(2.0f*U1[offset])-U0[offset]+((dt2*tempV*tempV)*(temp0*inv_dx02+temp1*inv_dx12));\n",
    "    \n",
    "    // Inject the forcing term at coordinates (P0, P1)\n",
    "    if ((i0==P0) && (i1==P1)) {\n",
    "        U2[offset]+=(1.0f-2.0f*pi2fm2t2)*exp(-pi2fm2t2);\n",
    "    }\n",
    "    \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d266b76-ce52-455e-a9b5-c37b5238307c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Problem setup\n",
    "\n",
    "For this problem we create the 2D grid as a square box of size $(N0,N1)=(256,256)$. The velocity is uniform at 343m/s. This is approximately the speed of sound in air. Then we use a Ricker wavelet as a forcing term to 'let off a firework' in the middle of the box and run a number of timesteps to see how a sound wave propagates in the box. \n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:80%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/wave2d_problem.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Problem setup for the 2D wave equation.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda1835-1595-438a-9d57-18f6839bc03c",
   "metadata": {},
   "source": [
    "The programs [wave2d_sync.cpp](wave2d_sync.cpp) and [wave2d_async.cpp](wave2d_async.cpp) setup a velocity and wavefield of size (N0, N1). At each timestep the kernel **wave2d_4o** is used to update the solution and a Ricker wavelet is injected into the middle of the box. Enough timesteps are alloted so that the wave propagates through the medium and reflects off the walls. Wavefield arrays that are no longer needed are recycled for efficiency.\n",
    "\n",
    "The Python code below readies the framework for plotting the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcced67c-c103-4ec3-b21e-e83a00f313de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from ipywidgets import widgets\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"../include\"))\n",
    "\n",
    "import py_helper\n",
    "\n",
    "float_type = np.float32\n",
    "\n",
    "defines=py_helper.load_defines(\"mat_size.hpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1637b9-c045-4b17-8492-a8a7c1f2f606",
   "metadata": {},
   "source": [
    "### Sequential (synchronous) IO solution\n",
    "\n",
    "In [wave2d_sync.cpp](wave2d_sync.cpp) we use an array of three HIP device allocations to represent the wavefield at timesteps (0,1,2). The null stream (stream 0) is used for both kernel execution and IO.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/sequential_io.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Sequential IO solution.</figcaption>\n",
    "</figure>\n",
    "\n",
    "#### Make and run the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e3ecc4-10ea-4f0c-8b9b-b62b61018e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for 'all'.\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bac6b827-4ee7-4f24-9cbe-bc856bc18691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device id: 0\n",
      "\tname:                                    \n",
      "\tglobal memory size:                      536 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    65 KB\n",
      "\tmaximum pitch size for memory copies:    402 MB\n",
      "\tmax block size:                          (1024,1024,1024)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,2147483647,2147483647)\n",
      "dt=0.001166, Vmax=343.000000\n",
      "dt=0.00116618, fm=34.3, Vmax=343, dt2=1.35998e-06\n",
      "The synchronous calculation took 43.580000 milliseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/wave2d_sync.exe'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([os.path.join(os.getcwd(),\"wave2d_sync.exe\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa42486-4d6f-4432-9c22-173f9f6c290d",
   "metadata": {},
   "source": [
    "#### Plot the output wavefield\n",
    "\n",
    "At the end of iteration a binary file containing the wavefield at every timestep is written to the file **array_out.dat**. We can read in this wavefield and plot it below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e385ad3-3850-4231-b005-35909c5d1374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edf0c06127240f3afe5c5d5aad3e03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=639), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the output file back in for display\n",
    "output_sync=np.fromfile(\"array_out.dat\", dtype=float_type)\n",
    "nimages_sync=int(output_sync.size//(defines[\"N0_U\"]*defines[\"N1_U\"]))\n",
    "images_sync=output_sync.reshape(nimages_sync, defines[\"N0_U\"], defines[\"N1_U\"])\n",
    "\n",
    "py_helper.plot_slices(images_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d690e0e-e7ab-4e33-a2aa-2988dfd62958",
   "metadata": {},
   "source": [
    "#### Application trace\n",
    "\n",
    "The script **make_traces.sh** produces traces in the **tau** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7d86a4-f911-4837-9917-2e4fcab10124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPL: on '230724_165528' from '/opt/rocm-5.6.0' in '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation'\n",
      "RPL: profiling '\"./wave2d_sync.exe\"'\n",
      "RPL: input file ''\n",
      "RPL: output dir '/tmp/rpl_data_230724_165528_29373'\n",
      "RPL: result dir '/tmp/rpl_data_230724_165528_29373/input_results_230724_165528'\n",
      "ROCProfiler: input from \"/tmp/rpl_data_230724_165528_29373/input.xml\"\n",
      "  0 metrics\n",
      "ROCtracer (29396):\n",
      "    HSA-trace(*)\n",
      "    HSA-activity-trace()\n",
      "    HIP-trace(*)\n",
      "Device id: 0\n",
      "\tname:                                    \n",
      "\tglobal memory size:                      536 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    65 KB\n",
      "\tmaximum pitch size for memory copies:    402 MB\n",
      "\tmax block size:                          (1024,1024,1024)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,2147483647,2147483647)\n",
      "dt=0.001166, Vmax=343.000000\n",
      "dt=0.00116618, fm=34.3, Vmax=343, dt2=1.35998e-06\n",
      "The synchronous calculation took 47.016000 milliseconds.\n",
      "\n",
      "ROCPRofiler: 643 contexts collected, output directory /tmp/rpl_data_230724_165528_29373/input_results_230724_165528\n",
      "hsa_copy_deps: 1\n",
      "scan hsa API data 18975:18976                                                                                                    hsa_copy_deps: 0\n",
      "scan hip API data 3222:3223                                                                                                    File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_sync.csv' is generating\n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_sync.stats.csv' is generating\n",
      "dump json 642:643                                                                                                    \n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_sync.json' is generating\n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_sync.hsa_stats.csv' is generating\n",
      "dump json 19618:19619                                                                                                    \n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_sync.json' is generating\n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_sync.copy_stats.csv' is generating\n",
      "dump json 637:638                                                                                                    \n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_sync.json' is generating\n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_sync.hip_stats.csv' is generating\n",
      "dump json 3222:3223                                                                                                    \n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_sync.json' is generating\n",
      "RPL: on '230724_165530' from '/opt/rocm-5.6.0' in '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation'\n",
      "RPL: profiling '\"./wave2d_async.exe\"'\n",
      "RPL: input file ''\n",
      "RPL: output dir '/tmp/rpl_data_230724_165530_29452'\n",
      "RPL: result dir '/tmp/rpl_data_230724_165530_29452/input_results_230724_165530'\n",
      "ROCProfiler: input from \"/tmp/rpl_data_230724_165530_29452/input.xml\"\n",
      "  0 metrics\n",
      "ROCtracer (29475):\n",
      "    HSA-trace(*)\n",
      "    HSA-activity-trace()\n",
      "    HIP-trace(*)\n",
      "Device id: 0\n",
      "\tname:                                    \n",
      "\tglobal memory size:                      536 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    65 KB\n",
      "\tmaximum pitch size for memory copies:    402 MB\n",
      "\tmax block size:                          (1024,1024,1024)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,2147483647,2147483647)\n",
      "dt=0.001166, Vmax=343.000000\n",
      "dt=0.00116618, fm=34.3, Vmax=343, dt2=1.35998e-06\n",
      "The asynchronous calculation took 30.273000 milliseconds.\n",
      "\n",
      "ROCPRofiler: 1282 contexts collected, output directory /tmp/rpl_data_230724_165530_29452/input_results_230724_165530\n",
      "hsa_copy_deps: 1\n",
      "scan hsa API data 29506:29507                                                                                                    hsa_copy_deps: 0\n",
      "scan hip API data 7722:7723                                                                                                    File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_async.csv' is generating\n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_async.stats.csv' is generating\n",
      "dump json 1281:1282                                                                                                    \n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_async.json' is generating\n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_async.hsa_stats.csv' is generating\n",
      "dump json 30788:30789                                                                                                    \n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_async.json' is generating\n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_async.copy_stats.csv' is generating\n",
      "dump json 0:1                                                                                                    \n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_async.json' is generating\n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_async.hip_stats.csv' is generating\n",
      "dump json 7722:7723                                                                                                    \n",
      "File '/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/rocprof_trace/wave2d_async.json' is generating\n"
     ]
    }
   ],
   "source": [
    "!./make_traces.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fa9b9-e925-4899-9ef5-9490a04d5e14",
   "metadata": {},
   "source": [
    "Then you can go to the address [https://ui.perfetto.dev](https://ui.perfetto.dev) to open the tracing utility. If you load the file **rocprof_trace/trace_sync.json** you should see something like this. The IO occurs after each kernel execution using the same command queue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fdcb5-31dd-4a66-b1a4-bef7e039546d",
   "metadata": {},
   "source": [
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/synchronous_io.png\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Sequential IO solution.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9d703-f3e4-4f1f-8434-3b24c32188ca",
   "metadata": {},
   "source": [
    "### Concurrent (asynchronous) IO solution\n",
    "\n",
    "In [wave2d_async.cpp](wave2d_async.cpp) is the solution for concurrent IO. The goal is to use **multiple streams** so that while one stream is executing a kernel the others are working on IO.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/concurrent_io.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Concurrent IO solution.</figcaption>\n",
    "</figure>\n",
    "\n",
    "In this example we are going to use a combination of stream and event-based synchronisation to highlight the different ways we can establish dependencies between workflows in HIP.\n",
    "\n",
    "#### Concurrent access to buffers is a bad idea\n",
    "\n",
    "It is a **race condition** to read from a device allocation (from another stream) at the same time as a kernel is writing to the allocation. Therefore, it is recommended to perform IO only on buffers that we **know for sure** are not being used. Our kernel needs access to wavefields at timesteps $\\textbf{U}_{0}, \\textbf{U}_{1}, \\textbf{U}_{2}$, therefore they are **not** safe to copy from, but wavefields at earlier timesteps e.g $\\textbf{U}_{-2}, \\textbf{U}_{-1}$ **are** safe to copy.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:30%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/wavefields.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Wavefields that are ok to copy.</figcaption>\n",
    "</figure>\n",
    "\n",
    "#### Using Events to aid with concurrency\n",
    "\n",
    "A solution to enable concurrent IO is to have an array of at least four memory allocations on the device to represent the wavefield. We choose an array of **nscratch=5** allocations to allow extra leeway for copies to finish. Associated with the buffers is an array of five streams for IO and one stream for compute. We also create an array of five events to demonstrate the use of events in workflow dependencies. During each iteration **n** of the time loop then:\n",
    "\n",
    "1. We use **hipStreamWaitEvent** to make the compute stream wait for past events arising from IO streams at **(n+2)** and **(n+1)**. \n",
    "1. For teaching purposes use **hipEventSynchronize** to make the host wait on the IO event at **n**.\n",
    "1. Then use **hipStreamSynchronize** on the compute stream to make sure there is no backlog of work.\n",
    "1. Submit the kernel to compute stream to solve for U[(n+2)%nscratch], then record an event (at index **n**) into the compute stream.\n",
    "1. The wavefield at **(n-1)** (which we call the *copy_index*) is safe to copy once the compute stream is done with it. Use **hipStreamWaitEvent** to make the IO stream at **(n-1)** wait on event at **(n-1)**. Then use the IO stream and **hipMemcpy3DAsync** to asynchronously copy the wavefield at **(n-1)** to the stack of output images. \n",
    "1. Use **hipStreamWaitEvent** so that the stream used for the copy waits for the kernel to finish. Record an event to the IO stream after the copy. These events will be then awaited on in the next iteration (step 1).\n",
    "\n",
    "The following diagram shows how the dependencies play out with events and streams during a single iteration.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/wavefields_concurrent.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Compute and IO queues during an iteration.</figcaption>\n",
    "</figure>\n",
    "\n",
    "The code for the iterations in [wave2d_async.cpp](wave2d_async.cpp) is produced here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce10d2-0688-4a30-892b-afff024c8eed",
   "metadata": {},
   "source": [
    "```C++\n",
    "    for (int n=0; n<NT; n++) {\n",
    "        \n",
    "        // Wait for the event associated with a stream\n",
    "        \n",
    "        // Can make a stream wait on an event\n",
    "        // Make the compute stream wait on previous copies\n",
    "        H_ERRCHK(hipStreamWaitEvent(compute_stream, events[(n+2)%nscratch], 0));\n",
    "        H_ERRCHK(hipStreamWaitEvent(compute_stream, events[(n+1)%nscratch], 0));\n",
    "        \n",
    "        // Or wait on an event directly\n",
    "        H_ERRCHK(hipEventSynchronize(events[n%nscratch]));\n",
    "        \n",
    "        // Can wait on a stream directly also\n",
    "        H_ERRCHK(hipStreamSynchronize(compute_stream));\n",
    "        \n",
    "        // Get the wavefields\n",
    "        U0_d = U_ds[n%nscratch];\n",
    "        U1_d = U_ds[(n+1)%nscratch];\n",
    "        U2_d = U_ds[(n+2)%nscratch];\n",
    "        \n",
    "        // Shifted time\n",
    "        t = n*dt-2.0*td;\n",
    "        pi2fm2t2 = pi*pi*fm*fm*t*t;\n",
    "        \n",
    "        // Launch the kernel using hipLaunchKernelGGL method\n",
    "        // Use 0 when choosing the default (null) stream\n",
    "        hipLaunchKernelGGL(wave2d_4o, \n",
    "            grid_nblocks, block_size, sharedMemBytes, compute_stream,\n",
    "            U0_d, U1_d, U2_d, V_d,\n",
    "            N0, N1, dt2,\n",
    "            inv_dx02, inv_dx12,\n",
    "            P0, P1, pi2fm2t2\n",
    "        );\n",
    "                           \n",
    "        // Check the status of the kernel launch\n",
    "        H_ERRCHK(hipGetLastError());\n",
    "          \n",
    "        // Insert an event into stream at n%nscratch\n",
    "        // It will complete afer the kernel does\n",
    "        H_ERRCHK(hipEventRecord(events[n%nscratch], compute_stream));   \n",
    "        \n",
    "        // Read memory from the buffer to the host in an asynchronous manner\n",
    "        if (n>2) {\n",
    "            size_t copy_index=n-1;\n",
    "            \n",
    "            // Insert a wait for the copy stream on the compute event\n",
    "            H_ERRCHK(\n",
    "                hipStreamWaitEvent(\n",
    "                    streams[copy_index%nscratch], \n",
    "                    events[copy_index%nscratch],\n",
    "                    0\n",
    "                )\n",
    "            );\n",
    "            \n",
    "            // Then asynchronously copy a wavefield back\n",
    "            // Using the copy stream\n",
    "            \n",
    "            // Only change what is necessary in copy_parms\n",
    "            copy_parms.srcPtr.ptr = U_ds[copy_index%nscratch];\n",
    "            \n",
    "            // Z positions of 1 don't seem to work on AMD platforms?!?!\n",
    "            copy_parms.dstPos.z = copy_index;\n",
    "            \n",
    "            // Copy memory asynchronously\n",
    "            H_ERRCHK(\n",
    "                hipMemcpy3DAsync(\n",
    "                    &copy_parms,\n",
    "                    streams[copy_index%nscratch]\n",
    "                )\n",
    "            );\n",
    "            // Record the event to a stream\n",
    "            H_ERRCHK(\n",
    "                hipEventRecord(\n",
    "                    events[copy_index%nscratch],\n",
    "                    streams[copy_index%nscratch]\n",
    "                )\n",
    "            );\n",
    "            \n",
    "            // Copy memory synchronously\n",
    "            //H_ERRCHK(\n",
    "            //    hipMemcpy3D(\n",
    "            //        &copy_parms\n",
    "            //        //streams[copy_index%nscratch]\n",
    "            //    )\n",
    "            //); \n",
    "        }\n",
    "    }\n",
    "```\n",
    "\n",
    "> With this example I used the function **hipMemcpy3DAsync** to copy wavefields as planes back to the host memory allocation. For some bizarre reason, during construction of this example I found that on AMD platforms a value of **copy_parms.dstPos.z=1** resulted in an error for calls to either **hipMemcpy3D** or **hipMemcpy3DAsync**. This strange behaviour was not present with the NVIDIA backend. I have worked around this issue by only copying planes when **n>2**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95733f27-00e3-492b-bea2-8bcbc0fe7881",
   "metadata": {},
   "source": [
    "#### Make and run the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e741744b-3f79-4d55-8046-b829ce17d635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for 'all'.\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582cea5a-05db-4afe-92ce-075a18bb95c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device id: 0\n",
      "\tname:                                    \n",
      "\tglobal memory size:                      536 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    65 KB\n",
      "\tmaximum pitch size for memory copies:    402 MB\n",
      "\tmax block size:                          (1024,1024,1024)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,2147483647,2147483647)\n",
      "dt=0.001166, Vmax=343.000000\n",
      "dt=0.00116618, fm=34.3, Vmax=343, dt2=1.35998e-06\n",
      "The asynchronous calculation took 26.425000 milliseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/toby/Pelagos/Projects/HIP_Course/course_material/L8_IO_Optimisation/wave2d_async.exe'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the application\n",
    "subprocess.run([os.path.join(os.getcwd(),\"wave2d_async.exe\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae90139d-e944-414c-a3ab-f95c10dcf5cd",
   "metadata": {},
   "source": [
    "If we check the time elapsed we find that the concurrent IO solution took less time than the sequential IO solution. A trace of the HIP activity shows that IO is taking place during compute.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/asynchronous_io.png\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Concurrent IO solution.</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e868c3-7c11-45bc-8b50-b8d5f8c803b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot the wavefield and explore results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459cbfd2-0fdc-4492-9805-f76db5e9a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fd855d518e4576a1b54fab74f4ce78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=639), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum residual between results is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Read the output file back in for display\n",
    "output_async=np.fromfile(\"array_out.dat\", dtype=float_type)\n",
    "nimages_async=int(output_async.size//(defines[\"N0_U\"]*defines[\"N1_U\"]))\n",
    "images_async=output_async.reshape(nimages_async, defines[\"N0_U\"], defines[\"N1_U\"])\n",
    "\n",
    "py_helper.plot_slices(images_async)\n",
    "\n",
    "print(f\"Maximum residual between results is {np.max(images_async-images_sync)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f9bf8-b44f-4527-8ac3-3ea81fe9a8f3",
   "metadata": {},
   "source": [
    "## Summary of learnings\n",
    "\n",
    "In this module we explored how IO can take place at the same time as a kernel using multiple streams. The concurrent IO solution was faster than the sequential IO solution. With concurrent IO it is a safety measure to avoid accessing memory allocations that are being used by a kernel, unless the allocated is managed. Both stream and event-based synchronisation can establish and enforce dependencies between activity that occurs across multiple streams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb824e5-856c-4b36-ac49-c3801294bc41",
   "metadata": {},
   "source": [
    "<address>\n",
    "Written by Dr. Toby Potter of <a href=\"https://www.pelagos-consulting.com\">Pelagos Consulting and Education</a> for the Pawsey Supercomputing Centre\n",
    "</address>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
