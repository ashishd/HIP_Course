{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da6d105-2df5-40a6-9baa-02497fcef0d8",
   "metadata": {},
   "source": [
    "# Measuring peformance in HIP applications\n",
    "\n",
    "Having an understanding of how well HIP applications perform is a vital part of the development process. The two main tools, **profiling** and **tracing** collect information about how well an application is performing. **Profiling** is the statistical collection of the cumulative time that threads spend in each program component. **Tracing** is a collection of both **when** and **for how long** threads spend in each application component. Since HIP applications use either an AMD or a CUDA backend, the profiling tools from each platform are available for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4bd9a5-220f-4ebc-99b5-fe753e6eca84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Event based profiling\n",
    "\n",
    "Events in HIP are used to check the progress of work that has been submitted and establish dependencies between workflows. They can also be used to time the execution of work such as kernels and memory copies. The code [mat_mult_profiling.cpp](mat_mult_profiling.cpp) contains a complete example where events are used to time the execution of the host to device memory copy as well as the timing of the matrix multiplication kernel. The data type **HipEvent_t** stores event data. \n",
    "\n",
    "### Source code changes\n",
    "\n",
    "In [mat_mult_profiling.cpp](mat_mult_profiling.cpp) we use the function **hipEventCreate** to create two events **t1** and **t2** as follows:\n",
    "\n",
    "```C++\n",
    "    // Create events for the memory copies and kernel runs\n",
    "    hipEvent_t t1=0, t2=0;\n",
    "    // Create the events\n",
    "    H_ERRCHK(hipEventCreate(&t1));\n",
    "    H_ERRCHK(hipEventCreate(&t2));\n",
    "```\n",
    "\n",
    "Now we wish to use these events to time the upload of host matrices **A_h** and **B_h** to the compute device. The HIP function **hipEventRecord** inserts the event into the \"flow\" of a stream. We haven't talked in depth about HIP streams yet and at this stage we can think of them as a queue to which work is submitted. Since we are not using a particular stream we are using the default stream (denoted by 0). We insert t1 into the default stream, perform the memory copies, and insert t2 after the copies are complete.\n",
    "\n",
    "```C++\n",
    "    // Start the recorder\n",
    "    H_ERRCHK(hipEventRecord(t1,0));\n",
    "    \n",
    "    // Peform the memory copies\n",
    "    H_ERRCHK(hipMemcpy(A_d, A_h, nbytes_A, hipMemcpyHostToDevice));\n",
    "    H_ERRCHK(hipMemcpy(B_d, B_h, nbytes_B, hipMemcpyHostToDevice));\n",
    "    \n",
    "    // Stop the recorder\n",
    "    H_ERRCHK(hipEventRecord(t2,0));\n",
    "```\n",
    "\n",
    "The function **hipEventSyynchronize** waits until events are complete. Then we can use the function **hipEventElapsedTime** to get the time elapsed between the two events. The helper function **h_get_event_time_ms** takes care of calling these functions, prints performance measurement information, and returns the number of milliseconds between the two events.\n",
    "\n",
    "```C++\n",
    "    // Total number of Bytes copied\n",
    "    size_t total_bytes = nbytes_A + nbytes_B;\n",
    "\n",
    "    // Get the elapsed time in milliseconds\n",
    "    float elapsed_ms = h_get_event_time_ms(t1, t2, \"memcpy\", &total_bytes);\n",
    "```\n",
    "\n",
    "The source code of **h_get_event_time_ms** is in <a href=\"../include/hip_helper.hpp\">hip_helper.hpp</a> and reproduced below:\n",
    "\n",
    "```C++\n",
    "// Get how much time elapsed between two events that were recorded\n",
    "float h_get_event_time_ms(\n",
    "        // Assumes start and stop events have been recorded\n",
    "        // with the hipEventRecord() function\n",
    "        hipEvent_t t1,\n",
    "        hipEvent_t t2,\n",
    "        const char* message, \n",
    "        size_t* nbytes) {\n",
    "    \n",
    "    // Make sure the stop and start events have finished\n",
    "    H_ERRCHK(hipEventSynchronize(t2));\n",
    "    H_ERRCHK(hipEventSynchronize(t1));\n",
    "\n",
    "    // Elapsed time in milliseconds\n",
    "    float elapsed_ms=0;\n",
    "\n",
    "    // Convert the time into milliseconds\n",
    "    H_ERRCHK(hipEventElapsedTime(&elapsed_ms, t1, t2));\n",
    "        \n",
    "    // Print the timing message if necessary\n",
    "    if ((message != NULL) && (strlen(message)>0)) {\n",
    "        std::printf(\"Time for event \\\"%s\\\": %.3f ms\", message, elapsed_ms);\n",
    "        \n",
    "        // Print transfer rate if nbytes is not NULL\n",
    "        if (nbytes != NULL) {\n",
    "            double io_rate_MBs = h_get_io_rate_MBs(\n",
    "                elapsed_ms, \n",
    "                *nbytes\n",
    "            );\n",
    "            std::printf(\" (%.2f MB/s)\", io_rate_MBs);\n",
    "        }\n",
    "        std::printf(\"\\n\");\n",
    "    }\n",
    "    \n",
    "    return elapsed_ms;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80de96-12f4-474c-b8e7-fcb4e0d50a24",
   "metadata": {},
   "source": [
    "We can reuse the events to time the execution of the kernel. \n",
    "\n",
    "```C++\n",
    "    // Record the kernel timer\n",
    "    H_ERRCHK(hipEventRecord(t1,0));\n",
    "\n",
    "    // Launch the kernel using hipLaunchKernelGGL method\n",
    "    hipLaunchKernelGGL(mat_mult, \n",
    "            grid_nblocks, \n",
    "            block_size, sharedMemBytes, 0, \n",
    "            A_d, B_d, C_d,\n",
    "            N1_A,\n",
    "            N0_C,\n",
    "            N1_C\n",
    "    );\n",
    "\n",
    "    // Stop the kernel timer\n",
    "    H_ERRCHK(hipEventRecord(t2,0));\n",
    "\n",
    "    // Get the elapsed time in milliseconds\n",
    "    elapsed_ms = h_get_event_time_ms(t1, t2, \"mat_mult kernel\", NULL);\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd3ff9-409d-4f1a-a692-24e512e58bcb",
   "metadata": {},
   "source": [
    "In this manner we instrument the uploads, downloads, and kernel execution in the source file [mat_mult_profiling.cpp](mat_mult_profiling.cpp). Now we run the instrumented code and view the timing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a7ca7f-acee-40b7-9ec5-30bd9d0ba996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: 'mat_mult_profiling.exe' is up to date.\n",
      "Device id: 0\n",
      "\tname:                                    \n",
      "\tglobal memory size:                      536 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    65 KB\n",
      "\tmaximum pitch size for memory copies:    536 MB\n",
      "\tmax block size:                          (1024,1024,1024)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,2147483647,2147483647)\n",
      "Time for event \"memcpy\": 0.476 ms (3341.60 MB/s)\n",
      "Time for event \"mat_mult kernel\": 5.442 ms\n",
      "Maximum error (infinity norm) is: 2.28882e-05\n"
     ]
    }
   ],
   "source": [
    "!make mat_mult_profiling.exe; ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0fa7d1-fc64-4eba-8717-3efbe6955045",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performance measurement with AMD tools\n",
    "\n",
    "#### HSA application traces\n",
    "\n",
    "```bash\n",
    "rocprof --hsa-trace -o amd_profiles/result.csv ./mat_mult_profiling.exe\n",
    "```\n",
    "\n",
    "Then in Google Chrome go to the address\n",
    "\n",
    "chrome://tracing\n",
    "\n",
    "to load **result.json**\n",
    "\n",
    "#### Performance counters\n",
    "\n",
    "Rocprof can collect performance counters on kernels. We specify a list of counters and the kernels they should apply to in the file **[rocprof_counters.txt](rocprof_counters.txt)**\n",
    "\n",
    "```bash\n",
    "rocprof -i rocprof_counters.txt --timestamp on --stats -o amd_profiles/result.csv ./mat_mult_profiling.exe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b2aaf2-ef12-44af-b96a-1e2a35a75082",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performance measurement with NVIDIA tools\n",
    "\n",
    "### Profiling with nvprof\n",
    "\n",
    "Historically there was limited functionality for profiling OpenCL events with NVIDIA's [NVVP](http://uob-hpc.github.io/2015/05/27/nvvp-import-opencl.html), however profiling support for OpenCL has largely disappeared, with the implementation of Nsight Compute and Nsight systems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a4568-4ac0-4def-9b6d-f0ddc7494176",
   "metadata": {},
   "source": [
    "## Performance measurement with Open-source tools\n",
    "\n",
    "### Tau\n",
    "\n",
    "[Tau](https://www.cs.uoregon.edu/research/tau/home.php) is a commonly used open-source profiling and tracing toolkit for HPC applications. For OpenCL applications it provides both profiling and tracing functionality.\n",
    "\n",
    "#### Profiling\n",
    "\n",
    "The Tau application **tau_exec** can be used to collect profiling information. Profiling information can then be visualised with the Tau applications **paraprof** (GUI), or **pprof** (command-line).\n",
    "\n",
    "We set the environment variables **PROFILEDIR=./tau** to tell Tau where to put files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7832d88-f179-467a-a1ee-edb71269b417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROFILEDIR=./tau\n"
     ]
    }
   ],
   "source": [
    "%env PROFILEDIR=./tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5afba1d-97d2-45b1-9f6b-d73b91b72fee",
   "metadata": {},
   "source": [
    "Then we use the following call to **tau_exec** to collect profiling information for opencl calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690edd47-7197-4853-a63a-ab9ad86bd26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t               name: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz \n",
      "\t global memory size: 16468 MB\n",
      "\t    max buffer size: 8234 MB\n",
      "\t     max local size: (8192,8192,8192)\n",
      "\t     max work-items: 8192\n",
      "device id: -1629247368.\n",
      "command id: 94891404868872.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 2 .TAU application\n",
      "Time for event \"Uploading Buffer A\": 0.216 ms (2461.77 MB/s)\n",
      "Time for event \"Uploading Buffer B\": 0.323 ms (3268.10 MB/s)\n",
      "Time for event \"Running kernel\": 53.618 ms\n",
      "Time for event \"Downloading Buffer C\": 0.456 ms (4706.89 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!tau_exec -T serial -opencl ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9338d-2708-4b49-99c8-90402390ffeb",
   "metadata": {},
   "source": [
    "Now have a look at the contents of the tau directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d759662c-caf0-4a14-b1c6-372512ba1ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.0.edf   profile.0.0.2  tau.trc\t\t  tautrace.0.0.2.trc\n",
      "profile.0.0.0  profile.txt    tautrace.0.0.0.trc  trace.json\n",
      "profile.0.0.1  tau.edf\t      tautrace.0.0.1.trc\n"
     ]
    }
   ],
   "source": [
    "!ls ./tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657c280-402b-434a-bb02-5aa1599fe54e",
   "metadata": {},
   "source": [
    "Use the Tau application **pprof** to get a text mode profile of the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc64ec07-40a3-4fc4-88e0-530a95acf3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pprof > ./tau/profile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adde27b-0d4f-440d-a042-bc8792ec5da3",
   "metadata": {},
   "source": [
    "We see from the profile that the call to **mat_mult** took approximately **12ms**. This is similar to what was measured from the profiling interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c5862-a647-4d86-909d-2522b8852954",
   "metadata": {},
   "source": [
    "#### Tracing with Google Chrome tracing\n",
    "\n",
    "For tracing we set the environment variables **TRACEDIR=./tau** **TAU_TRACE=1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a356019-c905-49c6-991e-ad2298b4d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TAU_TRACE=1\n",
      "env: TRACEDIR=./tau\n"
     ]
    }
   ],
   "source": [
    "%env TAU_TRACE=1\n",
    "%env TRACEDIR=./tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759ad7a-189f-4040-abcd-ae34777a5372",
   "metadata": {},
   "source": [
    "Capture OpenCL information as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c6b2ec1-47c5-4990-928c-be2ca33707e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t               name: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz \n",
      "\t global memory size: 16468 MB\n",
      "\t    max buffer size: 8234 MB\n",
      "\t     max local size: (8192,8192,8192)\n",
      "\t     max work-items: 8192\n",
      "device id: 2022348632.\n",
      "command id: 94684603067064.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 2 .TAU application\n",
      "Time for event \"Uploading Buffer A\": 0.180 ms (2955.50 MB/s)\n",
      "Time for event \"Uploading Buffer B\": 0.302 ms (3497.29 MB/s)\n",
      "Time for event \"Running kernel\": 52.092 ms\n",
      "Time for event \"Downloading Buffer C\": 0.499 ms (4305.15 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!tau_exec -T serial -opencl ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa4a15-cd9f-4fe7-a327-c13ed2fc8a58",
   "metadata": {},
   "source": [
    "Now merge the trace into a downloadable JSON document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef2b39c5-095f-4a1d-a5bb-5f1f832c2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tau/2.31.1/x86_64/bin/tau_merge -m tau.edf -e events.0.edf events.0.edf events.0.edf tautrace.0.0.0.trc tautrace.0.0.1.trc tautrace.0.0.2.trc tau.trc\n",
      "tau.trc exists; override [y]? tautrace.0.0.0.trc: 418 records read.\n",
      "tautrace.0.0.1.trc: 6 records read.\n",
      "tautrace.0.0.2.trc: 41 records read.\n"
     ]
    }
   ],
   "source": [
    "!cd tau; echo 'y' | tau_treemerge.pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8aa57a-1fc3-4881-9214-46f172cdb212",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd tau; tau_trace2json ./tau.trc ./tau.edf -chrome -ignoreatomic -o trace.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214adcb4-922f-4b26-b426-76207b50f0aa",
   "metadata": {},
   "source": [
    "<figure style=\"margin-left:0; margin-right:auto; width:100%;\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/Chrome_trace.png\">\n",
    "    <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Google Chrome tracing render.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65792d-d382-4dfb-8dbb-484d861fa839",
   "metadata": {},
   "source": [
    "In this instance we see that the kernel **mat_mult** has taken approximately 22ms to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38c04c-7c8d-4646-a382-0b02fb91a42e",
   "metadata": {},
   "source": [
    "<address>\n",
    "Written by Dr. Toby Potter of <a href=\"https://www.pelagos-consulting.com\">Pelagos Consulting and Education</a> for the Pawsey Supercomputing Centre\n",
    "</address>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
