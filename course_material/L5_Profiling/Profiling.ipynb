{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da6d105-2df5-40a6-9baa-02497fcef0d8",
   "metadata": {},
   "source": [
    "# Measuring peformance in HIP applications\n",
    "\n",
    "Having an understanding of how well HIP applications perform is a vital part of the development process. The two main tools, **profiling** and **tracing** collect information about how well an application is performing. **Profiling** is the statistical collection of the cumulative time that threads spend in each program component. **Tracing** is a collection of both **when** and **for how long** threads spend in each application component. Since HIP applications use either an AMD or a CUDA backend, the profiling tools from each platform are available for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4bd9a5-220f-4ebc-99b5-fe753e6eca84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Event based profiling\n",
    "\n",
    "Events in HIP are used to check the progress of work that has been submitted and establish dependencies between workflows. They can also be used to time the execution of work such as kernels and memory copies. The code [mat_mult_profiling.cpp](mat_mult_profiling.cpp) contains a complete example where events are used to time the execution of the host to device memory copy as well as the timing of the matrix multiplication kernel. The data type **HipEvent_t** stores event data. \n",
    "\n",
    "### Source code changes\n",
    "\n",
    "In [mat_mult_profiling.cpp](mat_mult_profiling.cpp) we use the function **hipEventCreate** to create two events **t1** and **t2** as follows:\n",
    "\n",
    "```C++\n",
    "    // Create events for the memory copies and kernel runs\n",
    "    hipEvent_t t1=0, t2=0;\n",
    "    // Create the events\n",
    "    H_ERRCHK(hipEventCreate(&t1));\n",
    "    H_ERRCHK(hipEventCreate(&t2));\n",
    "```\n",
    "\n",
    "Now we wish to use these events to time the upload of host matrices **A_h** and **B_h** to the compute device. The HIP function **hipEventRecord** inserts the event into the \"flow\" of a stream. We haven't talked in depth about HIP streams yet and at this stage we can think of them as a queue to which work is submitted. Since we are not using a particular stream we are using the default stream (denoted by 0). We insert t1 into the default stream, perform the memory copies, and insert t2 after the copies are complete.\n",
    "\n",
    "```C++\n",
    "    // Record the start event into the default stream\n",
    "    H_ERRCHK(hipEventRecord(t1,0));\n",
    "    \n",
    "    // Peform the memory copies\n",
    "    H_ERRCHK(hipMemcpy(A_d, A_h, nbytes_A, hipMemcpyHostToDevice));\n",
    "    H_ERRCHK(hipMemcpy(B_d, B_h, nbytes_B, hipMemcpyHostToDevice));\n",
    "    \n",
    "    // Record the stop event into the default stream\n",
    "    H_ERRCHK(hipEventRecord(t2,0));\n",
    "```\n",
    "\n",
    "The function **hipEventSynchronize** waits until events are complete. Then we can use the function **hipEventElapsedTime** to get the time elapsed between the two events. The helper function **h_get_event_time_ms** takes care of calling these functions, prints performance measurement information, and returns the number of milliseconds between the two events.\n",
    "\n",
    "```C++\n",
    "    // Total number of Bytes copied\n",
    "    size_t total_bytes = nbytes_A + nbytes_B;\n",
    "\n",
    "    // Get the elapsed time in milliseconds\n",
    "    float elapsed_ms = h_get_event_time_ms(t1, t2, \"memcpy\", &total_bytes);\n",
    "```\n",
    "\n",
    "The source code of **h_get_event_time_ms** is in <a href=\"../include/hip_helper.hpp\">hip_helper.hpp</a> and reproduced below:\n",
    "\n",
    "```C++\n",
    "// Get how much time elapsed between two events that were recorded\n",
    "float h_get_event_time_ms(\n",
    "        // Assumes start and stop events have been recorded\n",
    "        // with the hipEventRecord() function\n",
    "        hipEvent_t t1,\n",
    "        hipEvent_t t2,\n",
    "        const char* message, \n",
    "        size_t* nbytes) {\n",
    "    \n",
    "    // Make sure the stop and start events have finished\n",
    "    H_ERRCHK(hipEventSynchronize(t2));\n",
    "    H_ERRCHK(hipEventSynchronize(t1));\n",
    "\n",
    "    // Elapsed time in milliseconds\n",
    "    float elapsed_ms=0;\n",
    "\n",
    "    // Convert the time into milliseconds\n",
    "    H_ERRCHK(hipEventElapsedTime(&elapsed_ms, t1, t2));\n",
    "        \n",
    "    // Print the timing message if necessary\n",
    "    if ((message != NULL) && (strlen(message)>0)) {\n",
    "        std::printf(\"Time for event \\\"%s\\\": %.3f ms\", message, elapsed_ms);\n",
    "        \n",
    "        // Print transfer rate if nbytes is not NULL\n",
    "        if (nbytes != NULL) {\n",
    "            double io_rate_MBs = h_get_io_rate_MBs(\n",
    "                elapsed_ms, \n",
    "                *nbytes\n",
    "            );\n",
    "            std::printf(\" (%.2f MB/s)\", io_rate_MBs);\n",
    "        }\n",
    "        std::printf(\"\\n\");\n",
    "    }\n",
    "    \n",
    "    return elapsed_ms;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80de96-12f4-474c-b8e7-fcb4e0d50a24",
   "metadata": {},
   "source": [
    "We can reuse the events to time the execution of the kernel. \n",
    "\n",
    "```C++\n",
    "    // Record the start event into the default stream\n",
    "    H_ERRCHK(hipEventRecord(t1,0));\n",
    "\n",
    "    // Launch the kernel using hipLaunchKernelGGL method\n",
    "    hipLaunchKernelGGL(mat_mult, \n",
    "            grid_nblocks, \n",
    "            block_size, sharedMemBytes, 0, \n",
    "            A_d, B_d, C_d,\n",
    "            N1_A,\n",
    "            N0_C,\n",
    "            N1_C\n",
    "    );\n",
    "\n",
    "    // Record the stop event into the default stream \n",
    "    H_ERRCHK(hipEventRecord(t2,0));\n",
    "\n",
    "    // Get the elapsed time in milliseconds\n",
    "    elapsed_ms = h_get_event_time_ms(t1, t2, \"mat_mult kernel\", NULL);\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd3ff9-409d-4f1a-a692-24e512e58bcb",
   "metadata": {},
   "source": [
    "In this manner we instrument the uploads, downloads, and kernel execution in the source file [mat_mult_profiling.cpp](mat_mult_profiling.cpp). Now we run the instrumented code and view the timing results. Change directory to **L5_Profiling** and run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a7ca7f-acee-40b7-9ec5-30bd9d0ba996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: 'mat_mult_profiling.exe' is up to date.\n",
      "Device id: 0\n",
      "\tname:                                    \n",
      "\tglobal memory size:                      536 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    65 KB\n",
      "\tmaximum pitch size for memory copies:    536 MB\n",
      "\tmax block size:                          (1024,1024,1024)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,2147483647,2147483647)\n",
      "Time for event \"memcpy\": 0.382 ms (4159.90 MB/s)\n",
      "Time for event \"mat_mult kernel\": 3.139 ms\n",
      "Maximum error (infinity norm) is: 2.28882e-05\n"
     ]
    }
   ],
   "source": [
    "!make mat_mult_profiling.exe; ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec2892-86fe-46df-9e43-8446ebb8f977",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performance measurement with AMD tools\n",
    "\n",
    "The AMD profiler **ROCPROF** has the ability to collect traces and information from hardware performance counters.\n",
    "\n",
    "#### HIP application traces with rocprof\n",
    "\n",
    "An application trace is information on when functions execute and for how long they took to execute. Collecting HIP application traces with **rocprof** is accomplished with the **--hip-trace** flag. Tracing with **rocprof** only seems to work with the **AMD** backend at present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09e5d94-80c2-4f99-99c5-afc97c285458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPL: on '230214_151522' from '/opt/rocm-5.4.1' in '/home/toby/Pelagos/Projects/HIP_Course/course_material/L5_Profiling'\n",
      "RPL: profiling '\"./mat_mult_profiling.exe\"'\n",
      "RPL: input file ''\n",
      "RPL: output dir '/tmp/rpl_data_230214_151522_34364'\n",
      "RPL: result dir '/tmp/rpl_data_230214_151522_34364/input_results_230214_151522'\n",
      "ROCtracer (34384):\n",
      "    HIP-trace(*)\n",
      "Device id: 0\n",
      "\tname:                                    \n",
      "\tglobal memory size:                      536 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    65 KB\n",
      "\tmaximum pitch size for memory copies:    536 MB\n",
      "\tmax block size:                          (1024,1024,1024)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,2147483647,2147483647)\n",
      "Time for event \"memcpy\": 0.406 ms (3910.24 MB/s)\n",
      "Time for event \"mat_mult kernel\": 1.839 ms\n",
      "Maximum error (infinity norm) is: 2.28882e-05\n",
      "hsa_copy_deps: 0\n",
      "scan ops data 3:4                                                                                                    File 'rocprof_trace/result.copy_stats.csv' is generating\n",
      "dump json 2:3                                                                                                    \n",
      "File 'rocprof_trace/result.json' is generating\n",
      "File 'rocprof_trace/result.hip_stats.csv' is generating\n",
      "dump json 45:46                                                                                                    \n",
      "File 'rocprof_trace/result.json' is generating\n",
      "File 'rocprof_trace/result.stats.csv' is generating\n",
      "dump json 0:1                                                                                                    \n",
      "File 'rocprof_trace/result.json' is generating\n"
     ]
    }
   ],
   "source": [
    "!rocprof --hip-trace -o rocprof_trace/result.csv ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b616c5e-6096-427a-af49-74a933c7e64b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Inside the **rocprof_trace** folder you will find the following files:\n",
    "\n",
    "| file | purpose |\n",
    "| --- | --- |\n",
    "| profile.sysinfo.txt | System information on available devices |\n",
    "| profile.copy_stats.csv | Statistics on all IO calls |\n",
    "| profile.hip_stats.csv | Statistics on non-IO HIP function calls |\n",
    "| profile.stats.csv | Statistics on all kernel calls |\n",
    "| profile.db | SQLITE3 database of profiling information |\n",
    "| profile.json | Trace information in JSON format |\n",
    "\n",
    "We can load the trace file using a web browser. In a web browser you can go to this site for a user interface on viewing trace information.\n",
    "\n",
    "[https://ui.perfetto.dev/](https://ui.perfetto.dev/)\n",
    "\n",
    "Download the trace file **profile.json** to your computer and open it with the Perfetto UI in your web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3383f3-4c27-4daf-b506-68486ce77bd1",
   "metadata": {},
   "source": [
    "<figure style=\"margin-left:0; margin-right:auto; width:100%;\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/Perfetto_UI.png\">\n",
    "    <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Viewing rocprof application traces with Perfetto UI.</figcaption>\n",
    "</figure>\n",
    "\n",
    "If you zoom in you can see calls in GPU threads, COPY threads and HOST threads on the CPU. Notice how the **hipEventRecord** function is executed before and after the **hipMemcpy** calls and the **mat_mult** kernel execution. If you click on the **mat_mult** function you can see how long the kernel took to execute.\n",
    "\n",
    "<figure style=\"margin-left:0; margin-right:auto; width:100%;\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/Perfetto_UI_kernel.png\">\n",
    "    <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Determining the time for a kernel call</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb51c18-aeb9-47f5-b5c2-57d8d7ee99cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hardware performance counters with rocprof\n",
    "\n",
    "Hardware performance counters are devices in a processor that measure events, such as the number of wavefronts executed, or the number of times a cache is missed. Rocprof can collect performance counters on kernels. The type of performance counter information that can be captured is obtained with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bedf65ea-5b6d-4262-b447-d4839f33216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPL: on '230214_160116' from '/opt/rocm-5.4.1' in '/home/toby/Pelagos/Projects/HIP_Course/course_material/L5_Profiling'\n",
      "Basic HW counters:\n",
      "\n",
      "  gpu-agent0 : GRBM_COUNT : Tie High - Count Number of Clocks\n",
      "      block GRBM has 2 counters\n",
      "\n",
      "  gpu-agent0 : GRBM_GUI_ACTIVE : The GUI is Active\n",
      "      block GRBM has 2 counters\n",
      "\n",
      "  gpu-agent0 : GRBM_CP_BUSY : Any of the Command Processor (CPG/CPC/CPF) blocks are busy.\n",
      "      block GRBM has 2 counters\n",
      "\n",
      "  gpu-agent0 : GRBM_SPI_BUSY : Any of the Shader Pipe Interpolators (SPI) are busy in the shader engine(s).\n",
      "      block GRBM has 2 counters\n",
      "\n",
      "  gpu-agent0 : GRBM_TA_BUSY : Any of the Texture Pipes (TA) are busy in the shader engine(s).\n",
      "      block GRBM has 2 counters\n",
      "\n",
      "  gpu-agent0 : GRBM_GDS_BUSY : The Global Data Share (GDS) is busy.\n",
      "      block GRBM has 2 counters\n",
      "\n",
      "  gpu-agent0 : GRBM_EA_BUSY : The Efficiency Arbiter (EA) block is busy.\n",
      "      block GRBM has 2 counters\n",
      "\n",
      "  gpu-agent0 : GRBM_GL2CC_BUSY : The GL2CC block is busy.\n",
      "      block GRBM has 2 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_HIT[0-15] : Number of cache hits\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_MISS[0-15] : Number of cache misses.  UC reads count as misses.\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_MC_WRREQ[0-15] : Number of transactions (either 32-byte or 64-byte) going over the GL2C_EA_wrreq interface. Atomics may travel over the same interface and are generally classified as write requests. This does not include probe commands\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_EA_WRREQ_64B[0-15] : Number of 64-byte transactions going (64-byte write or CMPSWAP) over the TC_EA_wrreq interface.\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_MC_WRREQ_STALL[0-15] : Number of cycles a write request was stalled.\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_MC_RDREQ[0-15] : Number of GL2C/EA read requests (either 32-byte or 64-byte or 128-byte).\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_EA_RDREQ_32B[0-15] : Number of 32-byte GL2C/EA read requests\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_EA_RDREQ_64B[0-15] : Number of 64-byte GL2C/EA read requests\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_EA_RDREQ_96B[0-15] : Number of 96-byte GL2C/EA read requests\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : GL2C_EA_RDREQ_128B[0-15] : Number of 128-byte GL2C/EA read requests\n",
      "      block GL2C has 4 counters\n",
      "\n",
      "  gpu-agent0 : SQ_WAVES : Count number of waves sent to SQs. {emulated, global, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_WAVE_CYCLES : Number of clock cycles spent by waves in the SQs. Incremented by # of living (valid) waves each cycle. {nondeterministic, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_WAIT_INST_ANY : Number of clock cycles spent waiting for any instruction issue. In units of cycles. {nondeterministic}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_WAIT_ANY : Number of clock cycles spent waiting for anything. {nondeterministic, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INSTS_WAVE32 : Number of wave32 instructions issued, for flat, lds, valu, tex. {emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INSTS_WAVE32_LDS : Number of wave32 LDS indexed instructions issued. Wave64 may count 1 or 2, depending on what gets issued. {emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INSTS_WAVE32_VALU : Number of wave32 valu instructions issued. Wave64 may count 1 or 2, depending on what gets issued. {emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_WAVE32_INSTS : Number of instructions issued by wave32 waves. Skipped instructions are not counted. {emulated}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_WAVE64_INSTS : Number of instructions issued by wave64 waves. Skipped instructions are not counted. {emulated}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INST_LEVEL_GDS : Number of in-flight GDS instructions. Set next counter to ACCUM_PREV and divide by INSTS_GDS for average latency. {level, nondeterministic, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INST_LEVEL_LDS : Number of in-flight LDS instructions. Set next counter to ACCUM_PREV and divide by INSTS_LDS for average latency. Includes FLAT instructions. {level, nondeterministic, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INST_CYCLES_VMEM : Number of cycles needed to send addr and data for VMEM (lds, buffer, image, flat, scratch, global) instructions, windowed by perf_en. {emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQC_LDS_BANK_CONFLICT : Number of cycles LDS is stalled by bank conflicts. (emulated, C1)\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQC_LDS_IDX_ACTIVE : Number of cycles LDS is used for indexed (non-direct,non-interpolation) operations. {per-simd, emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INSTS_VALU : Number of VALU instructions issued excluding skipped instructions. {emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INSTS_SALU : Number of SALU instructions issued. {emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INSTS_SMEM : Number of SMEM instructions issued. {emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INSTS_FLAT : Number of FLAT instructions issued. {emulated, C2}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INSTS_LDS : Number of LDS indexed instructions issued. {emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_INSTS_GDS : Number of GDS instructions issued. {emulated, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : SQ_WAIT_INST_LDS : Number of clock cycles spent waiting for LDS (indexed) instruction issue. In units of cycles. {nondeterministic, C1}\n",
      "      block SQ has 8 counters\n",
      "\n",
      "  gpu-agent0 : TA_TA_BUSY[0-15] : TA block is busy. Perf_Windowing not supported for this counter.\n",
      "      block TA has 2 counters\n",
      "\n",
      "  gpu-agent0 : TA_FLAT_LOAD_WAVEFRONTS[0-15] :  Number of flat load vec32 packets processed by TA, same as flat_read_wavefronts in earlier IP\n",
      "      block TA has 2 counters\n",
      "\n",
      "  gpu-agent0 : TA_FLAT_STORE_WAVEFRONTS[0-15] : Number of flat store vec32 packets processed by TA, same as flat_write_wavefronts in earlier IP\n",
      "      block TA has 2 counters\n",
      "\n",
      "ROCPRofiler: 0 contexts collected\n"
     ]
    }
   ],
   "source": [
    "!rocprof --list-basic --list-derived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce2b350-4a1c-4408-b807-9b79e5f911c6",
   "metadata": {},
   "source": [
    "We can collect the total number of times these counters are triggered by specifying them in a file, such as in [rocprof_counters.txt](rocprof_counters.txt)\n",
    "\n",
    "```txt\n",
    "# GPUBusy: amount of time the GPU is working\n",
    "# Wavefronts: number of wavefronts exectued\n",
    "# L2CacheHit: percentage of time the execution found data in the L2 cache\n",
    "pmc : GPUBusy Wavefronts L2CacheHit\n",
    "range: 0:1\n",
    "gpu: 0\n",
    "kernel: mat_mult\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603e3d83-c918-4835-8667-9d823905f9b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Then we can use rocprof to collect the numbers from these counters as follows:\n",
    "\n",
    "```bash\n",
    "rocprof -i rocprof_counters.txt -o rocprof_counters/result.csv ./mat_mult_profiling.exe\n",
    "```\n",
    "\n",
    "If your chosen performance counters are supported, then the file [rocprof_counters/result.csv](rocprof_counters/result.csv) should contain a count for every time the counter was triggered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16d9e3-0dc9-478f-8d84-3f71f67579c9",
   "metadata": {},
   "source": [
    "### Tracing with Omnitrace\n",
    "\n",
    "[Omnitrace](https://github.com/AMDResearch/omnitrace) is an AMD research project to collect performance information on a program at runtime. It supports programs written in C, C++, Fortran and Python, as well as compute frameworks like OpenCL and HIP. We load the Omnitrace module using something like: \n",
    "\n",
    "```bash\n",
    "module load omnitrace/version\n",
    "```\n",
    "\n",
    "Then we can use Omnitrace to make a trace of **mat_mult_profiling.exe**.\n",
    "\n",
    "```bash\n",
    "cd omni_trace\n",
    "omnitrace -- ../mat_mult_profiling.exe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee8406-d101-4c4c-884e-a6a86cfc872f",
   "metadata": {},
   "source": [
    "If you look in the sub folder **omni_trace/omnitrace-mat_mult_profiling-output** there is a folder with the date of the trace. Download the **.proto** file and open it with [ui.perfetto.dev](https://ui.perfetto.dev) in a similar way to the json trace files from rocprof. You should see when and for how long functions are executed on the host and for how long kernels are executed on the device, along with a more detailed set of metrics such as CPU frequency and power consumption.\n",
    "\n",
    "<figure style=\"margin-left:0; margin-right:auto; width:100%;\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/omnitrace.png\">\n",
    "    <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Examining the output from Omnitrace using <a href=\"https://ui.perfetto.dev\">ui.perfetto.dev</a></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b2aaf2-ef12-44af-b96a-1e2a35a75082",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performance measurement with NVIDIA tools\n",
    "\n",
    "HIP applications that use the CUDA backend (i.e compiled with HIP_PLATFORM=nvidia) have access to the NVIDIA performance measurement tools such as [NVIDIA Nsight Systems](https://developer.nvidia.com/nsight-systems) and [NVIDIA Nsight Compute](https://developer.nvidia.com/nsight-compute). Here we briefly cover how to use these tools.\n",
    "\n",
    "### Tracing with Nsight Systems\n",
    "\n",
    "The command line application **nsys** can collect traces on **mat_mult_profiling.exe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8e3e699-6e16-431b-94f8-39c07100ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "Device id: 0\n",
      "\tname:                                    NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "\tglobal memory size:                      6226 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    49 KB\n",
      "\tmaximum pitch size for memory copies:    2147 MB\n",
      "\tmax block size:                          (1024,1024,64)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,65535,65535)\n",
      "Time for event \"memcpy\": 0.152 ms (10464.39 MB/s)\n",
      "Time for event \"mat_mult kernel\": 0.452 ms\n",
      "Maximum error (infinity norm) is: 2.28882e-05\n",
      "Generating '/tmp/nsys-report-ce04.qdstrm'\n",
      "Failed to create '/home/toby/Pelagos/Projects/HIP_Course/course_material/L5_Profiling/nsys_trace/results.nsys-rep': File exists.\n",
      "Use `--force-overwrite true` to overwrite existing files.\n",
      "[1/1] [========================100%] nsys-report-077a.nsys-rep\n",
      "Generated:\n",
      "    /tmp/nsys-report-077a.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "!nsys profile -o nsys_trace/results ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451fd761-d14f-407b-afd4-319424719b78",
   "metadata": {},
   "source": [
    "Then you can use this command under Linux to view the application trace \n",
    "\n",
    "```bash\n",
    "nsys-ui nsys_trace/results.nsys-rep\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b9bfd-94ac-4158-bb20-300b732adf93",
   "metadata": {},
   "source": [
    "### Hardware collection with Nsight compute\n",
    "\n",
    "Nsight compute has the ability to collect hardware performance counters, however this ability needs either administrator access or access granted to performance counters at the OS level. If this access is possible then the following command will collect hardware performance counters on **mat_mult_profiling.exe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "220a1c36-8bb4-44ff-b508-1437fb28234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 9050 (/home/toby/Pelagos/Projects/HIP_Course/course_material/L5_Profiling/mat_mult_profiling.exe)\n",
      "Device id: 0\n",
      "\tname:                                    NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "\tglobal memory size:                      6226 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    49 KB\n",
      "\tmaximum pitch size for memory copies:    2147 MB\n",
      "\tmax block size:                          (1024,1024,64)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,65535,65535)\n",
      "Time for event \"memcpy\": 0.140 ms (11341.40 MB/s)\n",
      "==PROF== Profiling \"mat_mult\" - 0: 0%....50%....100% - 9 passes\n",
      "Time for event \"mat_mult kernel\": 200.655 ms\n",
      "Maximum error (infinity norm) is: 2.28882e-05\n",
      "==PROF== Disconnected from process 9050\n",
      "==PROF== Report: /home/toby/Pelagos/Projects/HIP_Course/course_material/L5_Profiling/ncu_counters/results.ncu-rep\n"
     ]
    }
   ],
   "source": [
    "!ncu -f -o ncu_counters/results ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd0f55-b0c0-48d1-98bd-b7be9ef65991",
   "metadata": {},
   "source": [
    "Then you can run the command:\n",
    "\n",
    "```bash\n",
    "ncu-ui\n",
    "```\n",
    "\n",
    "To view the hardware performance counter information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38c04c-7c8d-4646-a382-0b02fb91a42e",
   "metadata": {},
   "source": [
    "<address>\n",
    "Written by Dr. Toby Potter of <a href=\"https://www.pelagos-consulting.com\">Pelagos Consulting and Education</a> for the Pawsey Supercomputing Centre\n",
    "</address>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27880e-656b-4764-a7de-6e6cd626360d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
